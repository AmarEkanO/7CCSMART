\documentclass{llncs}
\usepackage{graphicx}
\usepackage{csquotes}


\begin{document}

\institute{King's College London\\
	Department of Informatics,\\
	School of Natural and Mathematical Sciences}
\author{Amar Menezes (1435460)\\
\texttt{amar.menezes@kcl.ac.uk}}
\title{Achieving Anonymity on the Internet}
\date{March 2014}
\maketitle

\begin{abstract} 
	The objective of this review is to educate the reader on Internet privacy and anonymity. This review is intended for people interested in researching privacy enhancing technologies and/or designing such systems. We begin with an overview of anonymity technologies and their design considerations. We follow it up with a detailed evaluation of the Tor network, attacks against it, how it defends against such attacks and compare that to another popular anonymity network. We conclude with discussing some of the open issues with Tor in an effort to encourage the reader to take up some of the challenges. 
\end{abstract}

\section{Introduction} \label{intro}
Anonymity is derived from the Greek word anonymia, meaning "without a name" or "namelessness". In a larger context of society to be anonymous means to be non-identifiable, unreachable and untraceable. It is an enabler of values such as privacy and liberty, upon which the foundations of democracy and freedom of speech are laid.

People seek anonymity on the internet for various reasons. Whistle-blowers exposing government or corporate misdoings, human rights activists reporting abuse from areas of conflict, members of stigmatized groups seeking advice and help without the fear of being identified and ostracised, journalists reporting from countries with severe press censorship and normal people who wish to protect their privacy from unscrupulous marketeers and irresponsible corporations \cite{seekanonymity}.

In section \ref{intro} we introduced the need for internet anonymity and the people that benefit from it. Section \ref{background} gives a chronological summary of the evolution of privacy enabling technologies to the present day. In Section \ref{taxonomy} we discuss a framework to classify anonymity properties, adversary capabilities, network topology and metrics to measure anonymity. 
In Section \ref{tor} we review Tor, its design goals, assumptions and architecture. Section \ref{tor_attack_defence} analyses attacks against Tor and its defences. Section \ref{comparison} compares Tor with another contemporary anonymity network. Section \ref{openissues} discusses the open issues with the Tor network and encourages the reader to take up some of these challenges. We conclude in Section \ref{conclusion}.

\section{Background} \label{background}
\subsection{Evolution of privacy enabling technologies}

In the early days of the internet email was the primary form of electronic communication. The early efforts to bring internet privacy were focused on protecting email communications. Chaum proposed a untraceable mail system\cite{chaum-mix} known as a mix network. A mix network was a distribution of computer systems that would receive messages, remove identifying information about its origins and resend the message to its intended destination. Mixes would operate periodically collecting messages over a certain period of time and then outputting uniformly sized lexicographically ordered batches.

Dining Cryptographers Network (or DC-nets) \cite{chaum-dc} was another of Chaums proposals. Unlike mix networks, DC-nets required participants to broadcast their messages simultaneously, with no participant-to-participant communication. DC-nets provide low latency and are resistant to traffic analysis. However to DC-nets rely on largely on honest participants. A malicious participant could disrupt the broadcast without being traced causing the system to fail. Moreover the computational cost of making DC-nets fault tolerant to such attacks is prohibitively high, which is an impediment to its deployability. Some researchers have tried to address these scalability issues \cite{golle:eurocrypt2004}.

The anon.penet.fi was probably the earliest and most famous of pseudonymous remailers. It would purge identifying headers form outbound remailed messages. It also supported sender anonymity by providing the user with a random pseudonym. The remailer maintained a table that matched pseudonyms with the senders real email address. These very early implementations of remailers were known as Type 0 remailers. Due to their simplistic design the users could be easily traced if the maping table were compromised.

Type I remailers (popularly known as Cyberpunk remailers) were designed to address this problem. It dropped the support for pseudonym tables and could now accepted encrypted email. Email was then decrypted and remail it to its destination. This prevented an attacker try to perform message based co-relation on incoming and outgoing traffic. Type I remailers could also be chained together to allow for a higher level of anonymity. Each remailer in the network would knows only about the previous remailer that sent it a message. Thus an attacker would have to compromise all the remailers in the network to trace a message. This allowed us to take advantage of using a distributed network of remailers, giving us security by numbers. Type I remailers could also reorder messages to prevent time based co-relation attacks on traffic.

Although an improvement over Type 0 remailers, Type I remailers were susceptibility to message size based correlation attacks and replay attacks. To mitigate these limitations 'Mixmaster' or Type II remailer was developed. Type II remailers always use chaining and encryption. To prevent message size based co-relation attacks messages were padded to a constant length. To prevent time based co-relation attacks continuously generated random traffic was inserted into the communication channel. To prevent replay attacks, Mixmaster 2.0 maintained list of recent message IDs and would discard messages that it had received previously \cite{mixmaster-spec}.

Mixmaster was certainly superior to its predecessors Type 0 and Type I remailers, but it had functional limitations and security weaknesses. One major limitation of Mixmaster was the problem of replying to anonymous messages. To reply one had to resort to using the older and less secure Type I remailer. The defences against replay attacks were easily subverted. Mixmaster would cache the ID's of received messages but would store them for a fixed interval of time. An attacker would just have to wait till the entries expire and replay the messages. Additionally Mixmaster did not have a consistent way of distributing information about remailer availability, performance and encryption keys to participants. This allowed attackers to mount partitioning attacks to compromise remailer security. To address these issues Mixminion or Type III remailers were introduced \cite{minion-design}.

By 1997 remailers were well established as a privacy enabling technology. During that period researchers such as Ross Anderson and Adam Back were working on a platform that provided redundancy and resilience to censorship. Documents published via this platform could not be "unpublished". Anderson's proposed platform was called the Eternity Service \cite{anderson96eternity} which was later implemented by Back \cite{back:usenet}. Projects such as PipeNet\cite{pipenet10} and Onion Routing \cite{onion-routing:ih96} took the initiative to develop a platform for general internet anonymity. PipeNet was eventually shelved due to lack of interest and never made it past the design stages. Onion Routing on the other hand was a promising candidate to build low latency anonymous networks. Unlike PipeNet, Onion Routing leaned more towards performance and robustness. PipeNet preferred security over performance and would terminate its operation if its security was compromised in any way.

With more people using the Internet there has been a steady rise in the research for Internet privacy and anonymity. The Crowds network developed by Michael Reiter and Aviel Rubin at AT\&T Labs was one of the pioneering works in anonymizing web traffic \cite{crowds:tissec}. The users of Crowd would be grouped into large and geographically diverse groups. These groups would then collectively issue requests on behalf of its members. The idea was that to an observer the request could have come from any member of the Crowd network and even the members of the network would not be able to differentiate if the request was from the originator or just another member passing the message around the network. MorphMix\cite{morphmix:wpes2002}, P2P (previously known as Tarzan)\cite{tarzan:ccs02}, Herbivore\cite{herbivore:tr} and P5\cite{sherwood-protocol} were other attempts to develop similar low latency distributed anonymous networks.

In 2000 Zero-Knowledge Systems's Inc developed the Freedom Network \cite{freedom2-arch}, a PipeNet inspired low latency mix network. Unlike Crowds, Freedom Network was intended to be a commercial venture and there were significant costs to running and maintaining nodes in the network. Freedom was a high quality anonymity network but due to its high cost of operation it received little user acceptance.

\subsection{Extant technologies in the 21st century} \label{new_proj}

At the turn of the 21st century the Internet and World Wide Web had grown by leaps and bounds. Many projects on anonymizing internet traffic were proposed \cite{goldberg97privacyenhancing} \cite{fiveyearslater}, few were developed beyond their design stages and fewer still are in actual use.

In 2015 the most widely used anonymity networks are Tor \cite{tor-design} which is an implementation of Onion Routing, I2P (Invisible Internet Project) \cite{jrandom2003,zantout2011} and Freenet \cite{freenet} an Eternity Service inspired network. These projects have a large user base and are being actively developed by the open source community.

Some networks currently in development are GlobaLeaks \cite{globaleaks} which is an open source whistleblowing framework, FreedomBox \cite{freedom-box} which allows users to deploy personal servers running free software for private communications and Telex \cite{telex11} which is a new approach to achieving anti-censorship in Internet infrastructure. 

\subsection{The rising popularity of Tor}
The detailed discussion of all these technologies is beyond the scope of this review, instead we take up the discussion of the Tor network since it has been well researched by academia and has the largest user base among anonymity networks \cite{tor-metrics}.

Tor is a semi-distributed low latency mix network. It is run by volunteers who provide bandwidth and processing power to the network by setting up a Tor routers which allow users to connect to the internet anonymously. Tor is an implementation of Onion Routing which was originally developed by the U.S. Naval Research Laboratory. The project was handed over to the Electronic Frontier Foundation (EFF) in 2004 which oversaw the development and funding of the project. In 2006 two of the original authors of the project and five other developers founded the Tor Project, a non-profit research and education based organization based out of Massachusetts, US responsible for maintaining Tor. Since then in a span of eight years Tor grew from less than 2000 nodes to over 6000 nodes \cite{tor-metrics}.The EFF along with various Human Rights organizations, Privacy advocates, scientific research organisations and the public fund Tor.
 
What makes Tor so popular as compared to other networks is that it was designed to allow users could access the Internet anonymously. Other networks such as I2P do not natively support clear Internet access. Low latency was another design goal so that existing time sensitive internet applications could interoperate with Tor. Remailer technology such as Mixmaster and Mixminion are high latency networks and are unsuitable for applications such as web browsing, internet chat or remote administration.

In 2011, The Tor Project received the 2010 Award for Projects of Social Benefit form the Free Software Foundation. The organization was quoted saying
\begin{displayquote}
Using free software, Tor has enabled roughly 36 million people around the world to experience freedom of access and expression on the Internet while keeping them in control of their privacy and anonymity. Its network has proved pivotal in dissident movements in both Iran and more recently Egypt.\cite{free-software-foundation}
\end{displayquote}

\section{Describing Anonymity Technologies} \label{taxonomy}
Before we can begin a discussion about Tor,  we need a way to describe anonymity networks in general. Kelly et al. proposed a Cubic Taxonomy to describe anonymity properties, adversity capabilities and network topology \cite{kelly2012exploring}. This section is a summary of their work on Cubic Taxonomy and gives us an understanding of the underlying properties of anonymity networks.

\subsection{Anonymity properties}
The fundamental properties of anonymity are unidentifiability, unlinkibality and unobservability.\\

Unidentifiability is composed of four properties: 
\begin{itemize}
\item[]{\textbf{Sender Anonymity:} Is preserved when a particular message cannot be identified with a specific sender.}
\item[]{\textbf{Receiver Anonymity:} Is preserved when a particular message cannot be identified with a specific receiver.}
\item[]{\textbf{Mutual Anonymity:} This not only preserves Sender and Receiver Anonymity, but also ensures that the sender cannot identify the recipient and the recipient cannot identify the sender.}
\item[]{\textbf{Group Anonymity:} Is the same as Sender/Receiver Anonymity but when applied in the context of a group instead of individuals.}
\end{itemize}

Unlinkability is composed of three properties:
\begin{itemize}
	\item[]{\textbf{Location Anonymity:} Is preserved when a particular message is not linked to an individuals location or movement.}
	\item[]{\textbf{Communication Anonymity:} Is preserved when communication between sender receiver pairs stays undetected.}
	\item[]{\textbf{Group Communication Anonymity}: Is the same as Communication Anonymity but in the context of sender and receiver groups instead of individuals.}
\end{itemize}

The classical definition of Unidentifiability is composed of Sender and Receiver anonymity and Unlinkability consists only of Communication Anonymity \cite{terminology}. Kelly et al. \cite{kelly2012exploring} extend the definition under the Cubic Taxonomy by including Mutual Anonymity and Group Anonymity to Unidentifiability and Location Anonymity and Group Communication Anonymity to Unlinkability. They also noted the fact that at the time of publishing their work there were group anonymizing services that were in existence.

\subsection{Adversity capabilities}
An adversary is defined as an agent or a group of agents with an aim to degrade or eliminate anonymity. Understanding adversity capabilities helps us in developing a threat model for an anonymity network. Adversity capabilities are categorized as Reachability, Attackability and Adaptability.

\begin{itemize}
	\item[]{\textbf{Reachability:} An adversity's reach is either local or global. A global adversary has access to all the nodes and links in the network whereas a local adversary has access to only a portion of the network's nodes and links. The adversary reachability defines the extent of his knowledge of the system.}
	\item[]{\textbf{Adaptability:} An anonymous network can be either static or dynamic. In a static network the adversary's knowledge of the system and its targets remains constant during and after an attack. A dynamic network could prevent an adversary launching a successful attack but at the same time it could be leaking information to the adversary. In a static network the adversary's priori knowledge remains constant, but in a dynamic network the posterior knowledge could potentially increase.}
	\item[]{\textbf{Attackability:} An adversary can be passive or active in nature and internal or external to the network being attacked. A passive adversary typically observes and analyses the network. Passive attacks do not disrupt or modify the network communication in any way. An active adversary can mount attacks to disrupt or modify communication within the network.}
\end{itemize}

\subsection{ Network topology}
The Cubic Taxonomy \cite{kelly2012exploring} classifies anonymity networks as wired, wireless or a hybrid. These networks have schemes for  path selection, communication medium, topology and protocol implementations. These factors affect adversary capabilities and anonymity properties of a network. A brief summary of network categorization and its composition is given below.

Wired can be classified based on Path topology, Route scheme and Path type. It is assumed that the adversary has knowledge of these parameters during the attack. 
\begin{itemize}
	\item[]{\textbf{Path topology:} Topology routing are of two types, free/distributed or cascaded. In free/distributed routing the sender selects a path of variable length within the network to transfer messages. Free routing relies on the network infrastructure or participants to route messages anonymously. In cascade routing the sender can choose from a set of fixed paths to transfer messages.}
	\item[]{\textbf{Route Scheme:} Routing schemes within the network can be either Unicast like Tor or Multicast/Broadcast like in DC-nets. }
	\item[]{\textbf{Path Type:} Path Type selection is either cycle free or with cycles. In cycle free paths each node appears only once in the path. In paths where cycles are included, one strategy is to allow nodes to appear arbitrary number of times in the path with the exception that the start and end node remain fixed.}
\end{itemize}

Wireless networks are classified as Topology based or Position based. A Topology based network uses its link information to perform routing operations. Position based networks uses its nodes geolocation to perform routing operations. Each of these routing strategies use a proactive approach, reactive approach or a combination of both. In a proactive protocol, the nodes periodically exchange control information among themselves to make routing decisions and learn about network changes. A reactive protocol use an on-demand approach to generating routes. When users want to communicate the network sends out probes to create a route for communication. A hybrid protocol is a combination of both a proactive and reactive protocols.

\subsection{Mesauring Anonymity}
Consider a network with four members. Alice and Bob are members of this network and Bob wants to send Alice a message anonymously. If an adversary Eve believes that the message received by Bob was from one of the other three members in the network, then Sender Anonymity is preserved. However Receiver Anonymity is not preserved if Eve determines that Alice received the message.  Knowing that Alice was the recipient degrades communication anonymity since Eve can reduce the number of sender-receiver relationships. She can now eliminate the two other members of the network as recipients of the message.

Kelly et al. \cite{kelly2012exploring} reviewed several probabilistic and deterministic methods of measuring anonymity. This allows us to determine the level or change in anonymity of individual identities or the relationships between when under attack. Some of them are summarized below. 
\begin{itemize}
	\item[]{\textbf{Anonymity Set Size:} In this model the level of anonymity is a function of the total number of members. In a network of N members if C are compromised by an attacker. Then the level of anonymity reduces to a function of N-C members. If C is kept at zero then anonymity is preserved. If 1 \textless C \textless N then anonymity is degraded and eliminated when C = N-1.}
	\item[]{\textbf{K-Anonymity:} This model determines the level of anonymity by determining the minimum number of individuals or individual pairs that form part of the anonymity set. In the example of discussed previously, a 3-anonymity is achieved since Eve believes that one of the three members sent a message to Alice.}
	\item[]{\textbf{Individual Anonymity Degree:} In the Individual Anonymity Degree model, the adversary associates a probability of being exposed to each individual in the network. The adversary also sets a threshold value on the probability to determine if an individual is exposed. During the attack the adversary is constantly updating these values from the information learned from the network.}
	\item[]{\textbf{Entropy Anonymity:} This model determines the level of uncertainty or randomness in a given anonymity set. The higher the entropy in the probability distribution among individuals the harder it is for an adversary to determine the identities or relationships between individuals.}
\end{itemize}

\section{Overview of Tor} \label{tor}
Tor is a semi-distributed low latency mix network designed to anonymize TCP traffic. Dingledine et al. \cite{tor-design} describe the salient features of Tor, its design and architecture and attacks and defences of the network. This section summarises their work.
\subsection{Features}
The Tor network consists of nodes known as Onion Routers (OR). To communicate, clients randomly choose ORs to generate a path between the user and its intended destination. These paths are known as circuits. The node that connect the client to the network is knows as a Guard node and the node relaying traffic to outside the network is an Exit node. Each node in the circuit is aware of the next node and the previous node in the circuit and are oblivious to other nodes in the network. Messages are exchanged within the network in the form of cells. A cells relay control commands or data within the network and are 512 bytes long. Before the cell enters the circuit, it is encrypted with the session keys exchanged by between client and node. As it flows along the circuit each layer of encryption is decrypted and passed to the next node. This process of multiple encryptions at the client and decryptions at nodes is known as Onion Routing. 
\begin{itemize}
	\item[]{\textbf{Forward secrecy:} Tor clients negotiate session keys with each node in the circuit. Keys are periodically rotated so that recorded messages are not decrypted at a later stage.}
	\item[]{\textbf{Application Compatibility:} Tor opted to use the SOCKS proxy interface so that TCP applications could work with the network without any significant code changes.}
	\item[]{\textbf{TCP stream multiplexing:} Instead of building a separate circuit for each application that wanted to communicate, Tor allows multiple TCP streams to utilize the same circuit. The user can control which streams to allow or deny a circuit.}
	\item[]{\textbf{Redirecting traffic in transit:} Tor clients can redirect traffic flow along a circuit by changing the path partway. This helps in preventing traffic-shaping and message size co-relation attacks.}
	\item[]{\textbf{Directory authorities:} Tor uses trusted nodes known as Directory Authorities to distribute routing information to clients. These trusted nodes collaborate to maintain a list of trusted routers and their current state to requesters.}
	\item[]{\textbf{Configuration of Exit policies:} Node operators can configure the type of traffic that can exit from its nodes to reach the clear internet. The policy describes the hosts and ports the node will connect to.}
	\item[]{\textbf{Censorship resistance:} Tor allows its users to setup bridge nodes which circumvent attempts to block access to the network. These are not listed with the Directory authorities and is only known to the users of the bridge, this is done to prevent its IP address from being blocked.}
	\item[]{\textbf{Rendezvous points and hidden services:} The original Onion routing protocol required 'reply onions' to build circuits to connect to hidden services. Due to their always online and fixed keys, Reply onions did not preserve receiver anonymity. Tor improved upon this by allowing clients to negotiate rendezvous points to connect to hidden services, thus preserving receiver anonymity.}
\end{itemize}

\subsection{Design and Architecture}
Tor's design goals were that it must work with existing Internet infrastructure, be easy to implement and use and should be simple and flexible enough to be well understood and allow for security analysis. Some goals such as making it decentralized such as P2P networks, protection against end-to-end traffic analysis attacks and Normalization of Internet layer protocols have not been included to keep the design simple and deployable.

Each node in the Tor network is known as an Onion Router (OR). Each user runs an Onion Proxy (OP) to query Directory Authorities for router availability, create circuits and handle connections from user applications. OPs accept TCP data and multiplex them across circuits. ORs at the end of the circuits connect to the intended recipients and relay the data.

Every router in the network maintains two keys, a long term and short term key. One is a long term key used to sign TLS certificates, Router descriptors and the network directory. A router descriptor stores information about the router's keys, address, bandwidth, exit policy and so on. The long term key is known as the identity key. The short term key also called the onion key. The onion key is used to decrypt requests and to setup a circuit and exchange session keys. ORs communicate with each other using the TLS protocol. To prevent key compromise attacks the onion keys are periodically rotated and independently.

\subsubsection{Cells}
Fixed sized messages called cells are used for OR-OR and OP-OR communication. Each cell is 512 bytes in size and consists of a header and a payload. The header contains a circuit identifier and a command to for the recipient to decide what to do with the payload.
Cells can be either control cells or relay cells. Control cells are always interpreted by the node that receives it. Relay cells carry stream data. Relay cells have an additional header to identify the stream, a checksum for integrity, length of the payload and a relay command. The contents of a relay cell are encrypted/decrypted using 128-bit AES cipher in counter mode to generate a cipher stream.

\subsubsection{Circuits and Streams}
Circuits channel TCP streams within the Tor network. A circuit can be shared by multiple TCP streams. To prevent linkability new circuits are periodically created and old circuits discarded. Typically circuit rotation occurs once a minute. Circuit creation is initiated by the OP and is constructed by negotiating a symmetric key with each OR on the circuit one hop at a time. \\ 
The OP sends the first OR on the path a create command cell. Using Diffie-Hellman handshake they negotiate a key K. Once the circuit has been established messages are encrypted using the key K. To extend the circuit the OP sends a relay extend cell specifying the address of the next OR along with sufficient information to start a Diffie-Hellman key exchange with the next OR. If the circuit is extended successfully then a the newly added OR responds with the second half of the Diffie-Hellman key exchange and thus the OP and the newly added OR negotiate a key K'. To extend the circuit further the OP has to tell the last node in the circuit to extend to the next specified OR and a similar key exchange protocol is observed.

\subsubsection{Relay cells}
When a OR receives a relay cell it decrypts the relay header and payload with the key negotiated for that circuit. The OR validates the message integrity by validating the digest. If valid it accepts and processes the relay, if the check fails the circuit is destroyed.
To construct a relay cell the OP/OR adds a digest and then iteratively encrypts the payload with the keys negotiated for the circuit. It then forwards the cell to the next node in the circuit.
To tear down a circuit the OP sends a destroy control cell. Like circuit creation, tear down is an incremental process. Each OR that receives the destroy cell, closes all streams on that circuit and passes a new destroy cell to the next node until the final node is reached.
Similarly the OP can truncate a circuit by sending relay truncate cell to a single OR. The OR then sends a destroy cell to the forward circuit and extends the circuit to different nodes, without the intermediate nodes being aware of this change. Also if a OR in the circuit goes offline, the adjacent OR will send a relay truncated cell back to the OP. 

\subsubsection{Opening and Closing streams}
If the user's application wants to connect to a certain host and port, it request the OP to make a connection. The OP chooses a circuit and an exit node on that circuit. The OP via SOCKS then opens a stream by sending a relay begin cell to the exit node. Once the exit node connects to the remote host, it responds with a relay connected cell. Upon receipt the OP sends a SOCKS reply to notify the users application. Once the stream has been created, data from the user application is packaged into relay cells and sent along the circuit to the exit node.
Some applications perform a DNS lookup of the hostname before sending it along the circuit. This reveals the destination of the host to the DNS server compromising sender anonymity. Thus applications should prefer having hostnames resolved by the Tor client instead of the users applications.
A relay teardown cell is sent to the OR in case of an abnormal stream closure. In a normal stream closure a relay end cell is sent to the OR which replies with a relay end cell.

\subsubsection{Stream integrity checking}
Tor uses TLS to encrypt link communication to prevent external adversaries for modifying data. protecting against an internal adversary is a little more complex. Including hashes at each hop induces processing overhead and only verifies traffic from the OP to ORs. ORs cannot generate hashes for intermediate nodes since they don't know the session keys of other nodes. Moreover end-to-end timing attacks is a known issue with Tor, so tagging attacks reveal no additional data to the adversary.
Thus Tor opts to check message integrity at the stream edge. When a new hop is added to the circuit a SHA-1 digest is derived from the negotiated session key. These digests are added to the contents of all relay cells created, and include the first four bytes of the current digest.

\subsubsection{Rate limiting and fairness}
Tor allows the volunteers running the network to limit their bandwidth usage. Tor uses a token bucket approach to maintain a long term average rate will allowing short term burst above the allowed bandwidth.

\subsubsection{Congestion control}
To prevent bottlenecks in the network, Tor performs congestion control at the circuit level and stream level. Every OR maintains a packaging window and a delivery window. The packaging windows tracks how many relay data cells the OR is willing to transmit back to the OP and the delivery window tracks how many relay data cells it is willing to deliver to TCP streams outside the network. These windows are initialized to certain values and decremented each time a data cell is packaged or delivered the corresponding window is decremented. If the packaging window reaches zero the OR stops reading data from its TCP streams on the corresponding circuit. A relay sendme cell is sent to the OP with the stream id set to zero. The packaging window is incremented whenever an OR receives a relay sendme cell with stream id set to zero.
The OP keeps track of the packaging and delivery windows of each OR in the circuit. When the packaging windows reaches zero for an OR it stops reading from streams destined for that OR.

Stream level congestion control works in a similar way as circuit level congestion control, with the difference being that the OR checks if data has been successfully flushed onto the TCP stream before sending out relay sendme cells. If the data to be flushed is below a threshold value typically ten cells, then a relay sendme cell is sent to the OP.

\subsubsection{Rendezvous points and hidden services}
Tor allows its users to provide location-hidden services such as webservers while preserving receiver anonymity. This is achieved by using rendezvous points. The hidden service design allows the users to control access to the service by filtering incomming requests, this prevents an adversary from flooding the service with requests. The service is not tied to a single OR but can be migrated across multiple ORs, this is done to prevent a OR failure from crippling the service. Smear-resistance to rendezvous routers prevents them from being framed for objectionable content being provided by the hidden service.
The use of hidden services in Tor is as follows. The user generates a public key pair to identify the service. He then chooses several ORs to be introduction points to this service. He advertises these introduction points on a lookup service and signs them with the generated public key. The user then builds circuits to each of these introduction points and waits for requests.
Clients use a lookup service to get details about the hidden service. The client then chooses a OR as its rendezvous point (RP) to setup up a connection with the hidden service. The client creates a circuit to the RP and gives it a randomly chosen 'rendezvous cookie' to recognize the hidden service. The client then opens an anonymous stream to one of the introduction points advertised on the lookup service and gives it a message encrypted with the service's public key, telling it about the client, the RP, the rendezvous cookie and the start of a Diffie Hellman handshake. The introduction point sends the message to the hidden service which then decides if it wants to talk to the client or not.
If it decides to talk to the client, the hidden service builds a circuit to the clients RP and sends the rendezvous cookie, the second half of the Diffie Hellman cookie and a hash of the session key they now share. The RP now binds the clients circuit  to the circuit between the RP and the hidden service. The client can now start communicating by sending a relay begin cell along the circuit which is processed by the OP for the hidden service which then connects to the webserver. An anonymous stream has now been established for the clients to communicate with the service as if it were a normal webserver.

Introduction points are vulnerable to DoS attacks and measures must be taken by the operators of the hidden service to mitigate them. Some approaches are to increase the number of introduction points, provide clients with a current list or predicted list of unadvertised introduction points, etc.

\section{Attacks and Defences} \label{tor_attack_defence}
\begin{itemize}
	\item[]{\textbf{Passive Attacks}}
	\subitem{\textbf{Traffic observation:} Although an adversary cannot detect the users destination. It can observe traffic patterns of data sent and received. Although further processing may be required, users can be profiled based on their traffic patterns.}
	\subitem{\textbf{Content observation:} Data leaving from the user's end is encrypted so an adversary cannot view its contents, however data at the receivers end may not be encrypted. Tor does not filter content for identifying information and filtering tools such as Privoxy should be used to anonymize data streams.}
	\subitem{\textbf{Configuration distinguishability:} Different Tor users can have different configurations for their OPs, for example switching circuits more often. Although this may optimize Tor for the users needs, it may lose anonymity by appearing more distinct than the rest of the users. This assists the adversary in profiling users.}
	\subitem{\textbf{Time based co-relation attack:} An attacker that watches traffic patterns between clients and destination can confirm relationships with a high probability. Such co-relations are difficult to hide due to it being a low latency network. Possible defences are inserting dummy traffic, cloaking the connection between the OP and the first OR etc. This may restrict the capabilities of a local adversary, but is not a good defence against a global adversary.}
	\subitem{\textbf{Message size based co-relation attack:} Packet counting at endpoints is an effective way of confirming relationships, however the leaky pipe topology allows packets entering one end of the circuit to exit via different ORs thus frustrating a an adversary using message based co-relation attacks.}
	\subitem{\textbf{Website fingerprinting:} An adversary instead of searching exit connections for time or message based co-relation 	can build a database of 'fingerprints' based on the file sizes and access patterns of targeted websites. This database can latter be used to confirm user's connections at a later stage. Tor protects against this by having streams multiplexed within the same circuit and is limited to the granularity of cell sizes.}\\
	
	\item[]{\textbf{Active Attacks}}
	\subitem{\textbf{Compromised keys:} Compromising session keys will allow the attacker to decrypt control cells and a decrypt a layer of relay cells on every circuit on that connection. Learning the ORs private key allows him to impersonate the OR and must also learn the onion key to decrypt create cells for the keys lifetime. Periodic key rotation minimizes the risk of this attack. However if the attacker learns the ORs identity key then he can poison the directory servers with a forged descriptor thus granting full access to the node indefinitely.}
	\subitem{\textbf{System intrusion, Legal or Extralegal coercion:} Compromising each OR along a circuit by such means will lead the adversary to the end node. However the adversary needs to complete this within the lifetime of the circuit for it the circuit is changed the necessary information will have been discarded. Additionally forward secrecy prevents the adversary from forcing the node to decrypt recorded traffic once the circuit has been closed.}
	\subitem{\textbf{Malicious recepient:} An attacker running a malicious website can learn a users traffic patterns and can introduce arbitrary responses. This end to end attacks easier. Also the users application could leak identifying information to the rogue website further compromising anonymity.} 
	\subitem{\textbf{Malicious onion proxy:} If an attacker compromises an onion proxy all future connections from it will be compromised. This could happen if user have to connect to an OP located at a remote site or if the attacker gets users to run a subverted OP on their systems. This attack has been addressed by signing all Tor releases with an official public key and providing a list of secure release version to Directory Servers.}
	\subitem{\textbf{Traffic redirection:} Mounting a DoS attack against non-observable nodes can force traffic through adversary controlled nodes. The best defence against such an attack is robustness.}
	\subitem{\textbf{Watermarking attacks:} Cells can be modified at a hostile node to aid in confirming co-relations. This attack is prevented by integrity checks on cells.}
	\subitem{\textbf{Replay attacks:} Tor is resilient to replay attacks since replaying a handshake message negotiates a different session key each time so recorded messages cannot be reused.}
	\subitem{\textbf{Smear attacksL:} A adversary could use Tor for illegal or socially unacceptable acts, in the hopes of bringing down the network from bad press. Exit policies reduce the possibility of this abuse.}
	\subitem{\textbf{Unauthenticated protocols:} If unauthenticated protocols like HTTP are used, a rogue exit node could impersonate a target server and trick users into connecting to it. To prevent this attack users should prefer authenticated protocols such as HTTPS.}\\
	
	\item{\textbf{Attacks against Directory Servers}}
	\subitem{\textbf{Destroying servers:} If a few servers go offline, the remaining servers in operation can generate a consensus directory and broadcast network information. However if more than half the servers are taken offline the clients will need human intervention whether to trust the resulting directory.}
	\subitem{\textbf{Directory subversion:} If an adversary can subvert a directory server, he can influence the final directory. Subverting a majority of the directories allows the adversary to include compromised ORs into the final directory. To defend against this Directory Server operators need to be independent and attack-resistant.}
	\subitem{\textbf{Listing hostile or malfunctioning ORs:} The Tor threat model assumes that directory operators can filter out malicious ORs from the final directory.}\\
	\item{\textbf{Attacks against Rendezvous points}}
	\subitem{\textbf{Flooding introduction points:} By flooding introduction points with requests an attacker could possibly deny access to a hidden service. To protect against this introduction points block requests that lack authorization tokens. Additionally the service operator can limit the amount of request he is willing to serve or require the requester to solve a computational problem for each request made.}
	\subitem{\textbf{Disabling introduction points:} An attacker could disable the advertised introduction points to a hidden service and disrupt communication. Since the identity of a hidden service is attached to its public key and not to introduction points, the service can simply re-advertise itself at different introduction points.}
	\subitem{\textbf{Subverting an introduction point:} An attacker could compromise an introduction point  and flood the hidden service with requests or drop all valid requests from reaching the service. To defend against this attack the hidden service should be able to detect a flood and close the circuit and periodically send the introduction point a rendezvous request and ensure that the request reaches the service.}  
\end{itemize}

\section{Comparison with I2P} \label{comparison}
The Invisible Internet Project (I2P) \cite{jrandom2003,zantout2011} a fully distributed anonymous mix network that uses 'Garlic Routing', a derivative of Onion Routing to transmit messages across the network. The term Garlic Routing was first introduced by Michael J. Freedman. Instead of sending a single message, multiple messages are bundled together and sent through the network \cite{garlic-routing}. I2P was designed to be a dark net providing applications such as web browsing, file sharing, message communication such as IRC and email. Over the years I2P has received a steady stream of interest from people seeking internet privacy and from academia. It is currently the second most popular anonymity service after Tor but not as mature.
\begin{itemize}
	\item[]{\textbf{Goals:} Tor was designed and optimized for exit traffic whereas I2P was to provide hidden services. Anonymity cannot be directly measured since their threat models vary.} 
	\item[]{\textbf{Network Topology:} Tor uses Directory Servers to manage and distribute information about the network. This reduces complexity at each node and protects against Sybil attacks \cite{sybil}. I2P uses a distributed network database and peer selection to manage the network. Rather than trusting peer advertised capacity, I2P selects peers based on performance ranking and profiling.}
	\item[]{\textbf{Clear Internet access:} Tor provides exit nodes that allow its users to connect to the clear internet. I2P was not designed with this functionality in mind. Outproxies can be built to connect I2P traffic to the clear internet, however browsing experience may not be as elegant as Tor \cite{ehlert2011:usability-comparison-i2p-tor}}
	\item[]{\textbf{Message path creation:} Tor circuits support bi-directional traffic whereas I2P tunnels (which are counterparts to circuits in Tor) support uni-directional traffic. This effectively doubles the number of nodes an adversary has to subvert to compromise communication.However each peer now has to maintain a tunnel to each other peer it is communicating with.}
	\item[]{\textbf{Bandwidth:} Nodes in I2P have low bandwidth overhead since they participate in routing for other peers. In Tor client nodes (OPs) don't participate in routing activities and hence have negligible bandwidth overhead. However high capacity ORs are required for higher throughput and low latency.}
	\item[]{\textbf{Transport:} Tor currently supports only TCP streams, whereas I2P supports both TCP and UDP streams.}
	\item[]{\textbf{Support:} Tor has benefits from having more developers, better funding and is actively researched in academia. I2P is still under development and lacks the visibility and maturity Tor enjoys.}
\end{itemize}


\section{Open issues and Future work} \label{openissues}
In this section we discuss some of the existing issues with Tor and future work that needs to be done to improve the network. Design goals that were not part of the original Tor design such as decentralised peer-to-peer structure, protocol normalization and protection against end to end attacks may have to be factored in as the network grows. Denial of Service attacks such as CPU resource consumption or taking ORs offline have yet to find acceptable solutions. Exit policy abuse is one of the most serious challenges faced by Tor. Adversaries could implicate exit nodes of being complicit in malicious and threaten volunteers with legal action. Tor's configurable exit policy helps mitigate this to a certain extent. For example SMTP is blocked by default at Tor exit nodes. Till date no Tor operator has been convicted and in some cases the EFF provides legal help in responding to cease and desist notices.

Dingledine et al. \cite{tor-design} suggested a few areas where further research and development is required for the Tor network. At the top of their list is Scalability. The current semi-centralized structure would not scale past a few hundred nodes and a more elegant approach would be required to distribute network state information to clients. Nodes in the network are assumed to have decent bandwidth and latency, instead they suggest that nodes should advertise their bandwidth capacity to avoid congestion issues. Adding cover traffic to frustrate end to end attacks is another topic of debate. Weighing the security benefits to cost of performance is research area that needs to be looked at.
At the heart of the Tor network are its volunteers, the greater the diversity of the network the higher the level of anonymity offered to its users. Apart from proving routing services, there is also a need for additional scrutiny of the specification for security vulnerabilities. 

\section{Conclusion} \label{conclusion}
This literature review we looked at the need for privacy enabling technologies their evolution from the late 90s to the present day. We then described a framework to allow the reader to gain a fundamental understanding of anonymity properties, classification of anonymity networks, threat modelling and metrics on how to measure anonymity.
Furthermore we analysed the Tor network as a case study. We summarized its design goals, architecture, and typical attacks against it. We also discuss some of the questions that still exist with the network and possible direction on future work.
We also briefly mentioned some anonymity projects under active development in section \ref{new_proj}, in the hope that the reader might look them up and possibly contribute to these projects.

\bibliographystyle{plain}
\bibliography{bibliography}
\end{document}
